{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "93CEbzEyu29p"
   },
   "source": [
    "#  Part 1: CIFAR10 with fully connected layers\n",
    "\n",
    "@Author: <b>Akshat Tyagi (at3761)</b><br>\n",
    "\n",
    "\n",
    "This is the first section. \n",
    "\n",
    "## Goal\n",
    "Here I have attempted to implement a fully connected feed forward neural network in order to classify images into correct classes using the CIFAR10 Dataset. This is an attempt to display my understanding of the workings of a neural network. To that end, implementation of the network has been done using just numpy. \n",
    "<br><br>\n",
    "The main goal is to reach <b>accuracy of above 50% in the test set</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qzKa31O-yQnu"
   },
   "source": [
    "## Installations\n",
    "\n",
    "The following cells are used to install dependencies that are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "CfwgdUzlRCZh",
    "outputId": "796d5127-42c6-4e0e-a30c-fe7854c7f13f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==0.3.0.post4 from http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n",
      "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl (592.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 592.3MB 97.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (1.14.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (3.13)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-0.3.0.post4\n"
     ]
    }
   ],
   "source": [
    "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zyeL30EcSoPT"
   },
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "from os import path\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "\n",
    "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "RoBear29St2q",
    "outputId": "710bf637-3f63-4203-c837-9b2e60c9b837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.2.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.3.0.post4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch->torchvision) (3.13)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OZGG6qFqycga"
   },
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "oWh66iU2S0GF",
    "outputId": "d3b2a71d-b1e3-45c9-eb92-b6fa0fd9dd8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /data/cifar-10-python.tar.gz\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "transform = transforms.Compose(\n",
    "  [\n",
    "      transforms.ToTensor(), \n",
    "      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "  ]\n",
    ")\n",
    "\n",
    "# create dataset objects\n",
    "trainset = torchvision.datasets.CIFAR10(root='/data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# load images\n",
    "trainingset_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "testingset_loader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nIteIH3oyu4h"
   },
   "source": [
    "Modeling the data to be usable by numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zsuxkB5aTh8m"
   },
   "outputs": [],
   "source": [
    "enumeratedTrainset = enumerate(trainset)\n",
    "X = np.empty((50000,3,32,32),dtype=float)\n",
    "Y = np.empty((50000),dtype=int)\n",
    "for i,v in enumeratedTrainset:\n",
    "    val = v[0].numpy()\n",
    "    label = v[1]\n",
    "    X[i] = val\n",
    "    Y[i] = label\n",
    "    \n",
    "mean_image = np.mean(X, axis=0)\n",
    "X -= mean_image\n",
    "\n",
    "enumeratedTestSet = enumerate(testset)\n",
    "X_test = np.empty((10000,3,32,32),dtype=float)\n",
    "Y_test = np.empty((10000),dtype=int)\n",
    "for i,v in enumeratedTestSet:\n",
    "    val = v[0].numpy()\n",
    "    label = v[1]\n",
    "    X_test[i] = val\n",
    "    Y_test[i] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DbUwuMaSyzkG"
   },
   "source": [
    "## Main Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NnouHGLAz2_L"
   },
   "source": [
    "Designed an architecture that has the following features:\n",
    "*   4 fully connected hidden layers \n",
    "*   ReLU activation at every layer\n",
    "*   SGD, Learning Rate:3.113669e-01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dNEHLwJ0iwN_"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "  \n",
    "  def __init__(self, num_layers, layer_dimensions, drop_prob, reg_lambda = 0):\n",
    "    \n",
    "    self.reg = reg_lambda\n",
    "    self.num_layers = 1 + len(layer_dimensions)\n",
    "    self.params = {}\n",
    "    self.weight_scale = 2.461858e-02 \n",
    "    self.fc_cache = {}\n",
    "    self.relu_cache = {}\n",
    "    self.batch_size = 250\n",
    "    \n",
    "    input_dim = 3*32*32\n",
    "    \n",
    "    for i in range(self.num_layers - 1):\n",
    "      self.params['W' + str(i+1)] = np.random.normal(0, self.weight_scale, [input_dim, layer_dimensions[i]])\n",
    "      self.params['b' + str(i+1)] = np.zeros([layer_dimensions[i]])\n",
    "      input_dim = layer_dimensions[i]  \n",
    "\n",
    "    self.params['W' + str(self.num_layers)] = np.random.normal(0, self.weight_scale, [input_dim, 10])\n",
    "    self.params['b' + str(self.num_layers)] = np.zeros([10])\n",
    "\n",
    "  \n",
    "  def relu (self, x):\n",
    "    '''\n",
    "    Relu activation function\n",
    "    :param x: input value\n",
    "    '''\n",
    "    relu_func = lambda x: max(0,x)\n",
    "    return relu_func\n",
    "  \n",
    "  \n",
    "  def affineForward(self, A, W, b):\n",
    "    '''\n",
    "    The affine forward pass\n",
    "    @param x: input matrix\n",
    "    @param w: weight matrix\n",
    "    @param b: bias matrix\n",
    "    '''\n",
    "    out = None\n",
    "    NN = A.shape[0]\n",
    "    reshaped_input = np.reshape(A, [NN, -1])\n",
    "    out = np.dot(reshaped_input, W) + b\n",
    "    cache = (A, W, b)\n",
    "    return out, cache\n",
    "  \n",
    "  def activationForward(self,x):\n",
    "    '''\n",
    "    This function applies relu activation function\n",
    "    @param x: Input\n",
    "    '''\n",
    "    out = None\n",
    "    out = x.copy()\n",
    "    out[out < 0] = 0\n",
    "    cache = x\n",
    "    return out, cache\n",
    "\n",
    "  def dropout(self, A, prob):\n",
    "    '''\n",
    "    @param A: Input Matrix\n",
    "    @param prob: A dropout probabilty percentage\n",
    "    '''\n",
    "    mask = (np.random.rand(*A.shape) < prob) / prob\n",
    "    out = A * mask\n",
    "    return out, mask\n",
    "\n",
    "  def forwardPropogation(self, X):\n",
    "    '''\n",
    "    This function ties together the forward pass\n",
    "    @param X: input image\n",
    "    '''\n",
    "    size = X.shape[0]\n",
    "    X = np.reshape(X, [size, -1])  \n",
    "    \n",
    "    for i in range(self.num_layers-1):\n",
    "        fc_act, self.fc_cache[str(i+1)] = self.affineForward(X, self.params['W'+str(i+1)], self.params['b'+str(i+1)])\n",
    "        relu_act, self.relu_cache[str(i+1)] = self.activationForward(fc_act)\n",
    "        X = relu_act.copy()\n",
    "        \n",
    "    scores, final_cache = self.affineForward(X, self.params['W'+str(self.num_layers)], self.params['b'+str(self.num_layers)])  \n",
    "    return scores, final_cache\n",
    "  \n",
    "  \n",
    "  def affineBackward (self, dAl, cache):\n",
    "    '''\n",
    "    This function performs the backward pass on the fully connected layers\n",
    "    @param dAl: Gradient\n",
    "    @param cache: The cached parameters from the forward pass\n",
    "    '''\n",
    "    x, w, b = cache\n",
    "    dx, dw, db = None, None, None\n",
    "    NN = x.shape[0]\n",
    "    reshaped_x = np.reshape(x,[NN, -1])\n",
    "    dx = np.dot(dAl, w.T)\n",
    "    dx = np.reshape(dx, x.shape)\n",
    "    dw = np.dot(reshaped_x.T,dAl)\n",
    "    db = np.sum(dAl, axis=0)\n",
    "    return dx, dw, db\n",
    "  \n",
    "\n",
    "  def activationBackward(self, dout, cache):\n",
    "    '''\n",
    "    This function is used to perfrom backward pass through the relu. Returns the gradient\n",
    "    '''\n",
    "    dx, x = None, cache\n",
    "    relu_mask = (x >= 0)\n",
    "    dx = dout * relu_mask\n",
    "    return dx\n",
    "\n",
    "  \n",
    "  \n",
    "  def backPropogation(self, scores, y, final_cache):\n",
    "    '''\n",
    "    This function basically controls the backward pass in through the layers\n",
    "    @param scores: Result of the forward pass \n",
    "    @param y: Real classes\n",
    "    @param final_cache: Cache to keep track of features and weights\n",
    "    '''\n",
    "    loss, grads = 0.0, {}\n",
    "    loss, dsoft = self.softmax_loss(scores, y)\n",
    "    loss += 0.5*self.reg*(np.sum(np.square(self.params['W'+str(self.num_layers)])))\n",
    "    \n",
    "    dx_last, dw_last, db_last = self.affineBackward(dsoft, final_cache)\n",
    "    \n",
    "    grads['W'+str(self.num_layers)] = dw_last + self.reg*self.params['W'+str(self.num_layers)]\n",
    "    grads['b'+str(self.num_layers)] = db_last\n",
    "\n",
    "    for i in range(self.num_layers-1, 0, -1):\n",
    "        drelu = self.activationBackward(dx_last, self.relu_cache[str(i)])\n",
    "        dx_last, dw_last, db_last = self.affineBackward(drelu, self.fc_cache[str(i)])\n",
    "        grads['W' + str(i)] = dw_last + self.reg * self.params['W' + str(i)]\n",
    "        grads['b' + str(i)] = db_last\n",
    "        loss += 0.5 * self.reg * (np.sum(np.square(self.params['W' + str(i)])))\n",
    "\n",
    "    return loss, grads    \n",
    "    \n",
    "  \n",
    "  def softmax_loss(self, x, y):\n",
    "    '''\n",
    "    This function implements the softmax function\n",
    "    @param x: Inputs\n",
    "    @param y: Output class\n",
    "    '''\n",
    "    shiftedLogits = x - np.max(x, axis=1, keepdims=True)\n",
    "    Z = np.sum(np.exp(shiftedLogits), axis=1, keepdims=True)\n",
    "    log_probs = shiftedLogits - np.log(Z)\n",
    "    probs = np.exp(log_probs)\n",
    "    N = x.shape[0]\n",
    "    loss = -np.sum(log_probs[np.arange(N), y]) / N\n",
    "    dx = probs.copy()\n",
    "    dx[np.arange(N), y] -= 1\n",
    "    dx /= N\n",
    "    return loss, dx\n",
    "\n",
    "  \n",
    "  def train(self, X, y, print_every=20, num_epochs=20, batch_size=250, alpha = 3.113669e-01):\n",
    "    '''\n",
    "    This is the training function where the main loop to train the designed architecture recides\n",
    "    @param X: The training set\n",
    "    @param y: The classes\n",
    "    @param print_every: Determines the number of iterations after which feedback is provided\n",
    "    @param num_epochs: The total number of epochs\n",
    "    @param batch_size: The batch size in use during the training process\n",
    "    @param alpha: The learning parameter\n",
    "    '''\n",
    "    num_train = X.shape[0]\n",
    "    iterations_per_epoch = max(num_train // batch_size , 1)\n",
    "    \n",
    "    num_iterations= 10000\n",
    "    print(\"Total iterations:\"+ str(num_iterations))\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "\n",
    "      num_train = X.shape[0]\n",
    "      batch_mask = np.random.choice(num_train, self.batch_size)\n",
    "      X_batch = X[batch_mask]\n",
    "      y_batch = y[batch_mask]\n",
    "      scores, final_cache = self.forwardPropogation(X_batch)\n",
    "      loss, grads = self.backPropogation(scores, y_batch, final_cache)\n",
    "      self.updateParameters(grads,alpha)\n",
    "      \n",
    "      if i % print_every == 0:\n",
    "        print(str(i)+\"/\"+str(num_iterations)+\" iterations done. At i=\"+str(i)+\" => | Loss: \"+str(loss) + \" | Accuracy:\"+str(self.accuracy(np.argmax(scores,axis=1),y_batch)))\n",
    "        \n",
    "    print(\"Done\")\n",
    "      \n",
    "  def updateParameters(self,gradients,alpha):\n",
    "    '''\n",
    "    This function updates the gradients obtained using gradient descent\n",
    "    @param gradients: Computed gradients through backpropogation\n",
    "    @param alpha: The learning rate for gradient descent\n",
    "    '''\n",
    "    for p, w in self.params.items():\n",
    "      dw = gradients[p]\n",
    "      prev_dw = dw\n",
    "      self.params[p] = self.params[p] - dw * alpha #alpha*dw\n",
    "           \n",
    "  def predict(self,X_test):\n",
    "    '''\n",
    "    This function is used to test the trined classifier by performing predictions on the test set\n",
    "    @param X_test: The test set\n",
    "    '''\n",
    "    y_pred = []\n",
    "    scores, cache = self.forwardPropogation(X_test)    \n",
    "    y_pred.append(np.argmax(scores, axis=1))                 \n",
    "    return y_pred\n",
    "  \n",
    "  def accuracy(self,y_pred,y_test):\n",
    "    '''\n",
    "    This function tests the accuracy of the trained model\n",
    "    @param y_pred: Predicted class \n",
    "    @param y_test: Actual Class\n",
    "    '''\n",
    "    y_pred = np.hstack(y_pred)\n",
    "    acc = np.mean(y_pred == y_test)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vGMuXG0wzKli"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 8450
    },
    "colab_type": "code",
    "id": "mY-RAYn18Ycl",
    "outputId": "62c6fbd0-3996-4d77-82a3-9392b2e2fb95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total iterations:10000\n",
      "0/10000 iterations done. At i=0 => | Loss: 2.302830998322575 | Accuracy:0.072\n",
      "20/10000 iterations done. At i=20 => | Loss: 2.2994755221733363 | Accuracy:0.144\n",
      "40/10000 iterations done. At i=40 => | Loss: 2.302746974420147 | Accuracy:0.092\n",
      "60/10000 iterations done. At i=60 => | Loss: 2.3026644416145445 | Accuracy:0.124\n",
      "80/10000 iterations done. At i=80 => | Loss: 2.2975250535943297 | Accuracy:0.092\n",
      "100/10000 iterations done. At i=100 => | Loss: 2.2864587852581457 | Accuracy:0.132\n",
      "120/10000 iterations done. At i=120 => | Loss: 2.1996987420876875 | Accuracy:0.168\n",
      "140/10000 iterations done. At i=140 => | Loss: 2.074822681753758 | Accuracy:0.196\n",
      "160/10000 iterations done. At i=160 => | Loss: 1.950701646514746 | Accuracy:0.212\n",
      "180/10000 iterations done. At i=180 => | Loss: 1.9340956424996398 | Accuracy:0.244\n",
      "200/10000 iterations done. At i=200 => | Loss: 1.9242730614541634 | Accuracy:0.276\n",
      "220/10000 iterations done. At i=220 => | Loss: 1.8088647606763852 | Accuracy:0.28\n",
      "240/10000 iterations done. At i=240 => | Loss: 1.9758578384794678 | Accuracy:0.272\n",
      "260/10000 iterations done. At i=260 => | Loss: 1.7946007169081615 | Accuracy:0.316\n",
      "280/10000 iterations done. At i=280 => | Loss: 1.8518306697140705 | Accuracy:0.32\n",
      "300/10000 iterations done. At i=300 => | Loss: 1.8008261389503077 | Accuracy:0.284\n",
      "320/10000 iterations done. At i=320 => | Loss: 1.7495128644943416 | Accuracy:0.376\n",
      "340/10000 iterations done. At i=340 => | Loss: 1.7135565661930876 | Accuracy:0.384\n",
      "360/10000 iterations done. At i=360 => | Loss: 1.6854857052070105 | Accuracy:0.372\n",
      "380/10000 iterations done. At i=380 => | Loss: 1.6427823598108318 | Accuracy:0.392\n",
      "400/10000 iterations done. At i=400 => | Loss: 1.713487586654758 | Accuracy:0.392\n",
      "420/10000 iterations done. At i=420 => | Loss: 1.5872625623061012 | Accuracy:0.388\n",
      "440/10000 iterations done. At i=440 => | Loss: 1.7736441640843572 | Accuracy:0.328\n",
      "460/10000 iterations done. At i=460 => | Loss: 1.6254524541582946 | Accuracy:0.372\n",
      "480/10000 iterations done. At i=480 => | Loss: 1.6425504384142626 | Accuracy:0.412\n",
      "500/10000 iterations done. At i=500 => | Loss: 1.662497328611089 | Accuracy:0.384\n",
      "520/10000 iterations done. At i=520 => | Loss: 1.686458792759693 | Accuracy:0.384\n",
      "540/10000 iterations done. At i=540 => | Loss: 1.6379403998991784 | Accuracy:0.408\n",
      "560/10000 iterations done. At i=560 => | Loss: 1.5479152179529552 | Accuracy:0.444\n",
      "580/10000 iterations done. At i=580 => | Loss: 1.459828302232429 | Accuracy:0.492\n",
      "600/10000 iterations done. At i=600 => | Loss: 1.5029775860457406 | Accuracy:0.468\n",
      "620/10000 iterations done. At i=620 => | Loss: 1.52295744701653 | Accuracy:0.452\n",
      "640/10000 iterations done. At i=640 => | Loss: 1.624737053147263 | Accuracy:0.452\n",
      "660/10000 iterations done. At i=660 => | Loss: 1.490292086209456 | Accuracy:0.456\n",
      "680/10000 iterations done. At i=680 => | Loss: 1.404046818634808 | Accuracy:0.48\n",
      "700/10000 iterations done. At i=700 => | Loss: 1.584089453677133 | Accuracy:0.432\n",
      "720/10000 iterations done. At i=720 => | Loss: 1.4989774314373585 | Accuracy:0.508\n",
      "740/10000 iterations done. At i=740 => | Loss: 1.3623005125819758 | Accuracy:0.528\n",
      "760/10000 iterations done. At i=760 => | Loss: 1.366788412947921 | Accuracy:0.5\n",
      "780/10000 iterations done. At i=780 => | Loss: 1.3018324950631488 | Accuracy:0.548\n",
      "800/10000 iterations done. At i=800 => | Loss: 1.4755575355787858 | Accuracy:0.464\n",
      "820/10000 iterations done. At i=820 => | Loss: 1.5340124188677782 | Accuracy:0.468\n",
      "840/10000 iterations done. At i=840 => | Loss: 1.537811554327965 | Accuracy:0.464\n",
      "860/10000 iterations done. At i=860 => | Loss: 1.4087957113176695 | Accuracy:0.48\n",
      "880/10000 iterations done. At i=880 => | Loss: 1.24195857414236 | Accuracy:0.556\n",
      "900/10000 iterations done. At i=900 => | Loss: 1.3079995060802057 | Accuracy:0.524\n",
      "920/10000 iterations done. At i=920 => | Loss: 1.3582027179176526 | Accuracy:0.452\n",
      "940/10000 iterations done. At i=940 => | Loss: 1.306920258019033 | Accuracy:0.48\n",
      "960/10000 iterations done. At i=960 => | Loss: 1.5295358580944194 | Accuracy:0.512\n",
      "980/10000 iterations done. At i=980 => | Loss: 1.2331270018591547 | Accuracy:0.54\n",
      "1000/10000 iterations done. At i=1000 => | Loss: 1.3959303713053108 | Accuracy:0.508\n",
      "1020/10000 iterations done. At i=1020 => | Loss: 1.4532915088759446 | Accuracy:0.448\n",
      "1040/10000 iterations done. At i=1040 => | Loss: 1.4017205333705396 | Accuracy:0.524\n",
      "1060/10000 iterations done. At i=1060 => | Loss: 1.146062186668983 | Accuracy:0.596\n",
      "1080/10000 iterations done. At i=1080 => | Loss: 1.2148431765983794 | Accuracy:0.528\n",
      "1100/10000 iterations done. At i=1100 => | Loss: 1.1791238094961505 | Accuracy:0.584\n",
      "1120/10000 iterations done. At i=1120 => | Loss: 1.2976187982546763 | Accuracy:0.504\n",
      "1140/10000 iterations done. At i=1140 => | Loss: 1.2709201051632286 | Accuracy:0.548\n",
      "1160/10000 iterations done. At i=1160 => | Loss: 1.324154927714584 | Accuracy:0.524\n",
      "1180/10000 iterations done. At i=1180 => | Loss: 1.2700803958150046 | Accuracy:0.576\n",
      "1200/10000 iterations done. At i=1200 => | Loss: 1.1626948505849486 | Accuracy:0.604\n",
      "1220/10000 iterations done. At i=1220 => | Loss: 1.2702481038222009 | Accuracy:0.572\n",
      "1240/10000 iterations done. At i=1240 => | Loss: 1.273090335594171 | Accuracy:0.576\n",
      "1260/10000 iterations done. At i=1260 => | Loss: 1.170307015891691 | Accuracy:0.572\n",
      "1280/10000 iterations done. At i=1280 => | Loss: 1.1350958958105997 | Accuracy:0.572\n",
      "1300/10000 iterations done. At i=1300 => | Loss: 1.1232307649342357 | Accuracy:0.576\n",
      "1320/10000 iterations done. At i=1320 => | Loss: 1.1641917102371433 | Accuracy:0.584\n",
      "1340/10000 iterations done. At i=1340 => | Loss: 1.1916372517124068 | Accuracy:0.6\n",
      "1360/10000 iterations done. At i=1360 => | Loss: 1.2597746939659409 | Accuracy:0.564\n",
      "1380/10000 iterations done. At i=1380 => | Loss: 1.2167976734596162 | Accuracy:0.568\n",
      "1400/10000 iterations done. At i=1400 => | Loss: 1.1240597404154886 | Accuracy:0.6\n",
      "1420/10000 iterations done. At i=1420 => | Loss: 1.0104837859270206 | Accuracy:0.636\n",
      "1440/10000 iterations done. At i=1440 => | Loss: 1.1611034870349815 | Accuracy:0.608\n",
      "1460/10000 iterations done. At i=1460 => | Loss: 1.2394777942706015 | Accuracy:0.584\n",
      "1480/10000 iterations done. At i=1480 => | Loss: 1.0793963741354802 | Accuracy:0.616\n",
      "1500/10000 iterations done. At i=1500 => | Loss: 1.1213271266163742 | Accuracy:0.604\n",
      "1520/10000 iterations done. At i=1520 => | Loss: 1.1356626126735683 | Accuracy:0.644\n",
      "1540/10000 iterations done. At i=1540 => | Loss: 1.2253242374716178 | Accuracy:0.556\n",
      "1560/10000 iterations done. At i=1560 => | Loss: 1.0417469294272208 | Accuracy:0.624\n",
      "1580/10000 iterations done. At i=1580 => | Loss: 1.1483672067333996 | Accuracy:0.636\n",
      "1600/10000 iterations done. At i=1600 => | Loss: 1.113209333131912 | Accuracy:0.636\n",
      "1620/10000 iterations done. At i=1620 => | Loss: 1.128847463111461 | Accuracy:0.604\n",
      "1640/10000 iterations done. At i=1640 => | Loss: 0.9996279140785342 | Accuracy:0.656\n",
      "1660/10000 iterations done. At i=1660 => | Loss: 1.0441725866628062 | Accuracy:0.656\n",
      "1680/10000 iterations done. At i=1680 => | Loss: 1.1691449822764926 | Accuracy:0.568\n",
      "1700/10000 iterations done. At i=1700 => | Loss: 1.0604060636731845 | Accuracy:0.6\n",
      "1720/10000 iterations done. At i=1720 => | Loss: 1.1286111628251057 | Accuracy:0.62\n",
      "1740/10000 iterations done. At i=1740 => | Loss: 1.112471907482009 | Accuracy:0.596\n",
      "1760/10000 iterations done. At i=1760 => | Loss: 1.097737945880338 | Accuracy:0.588\n",
      "1780/10000 iterations done. At i=1780 => | Loss: 0.9972796790136742 | Accuracy:0.648\n",
      "1800/10000 iterations done. At i=1800 => | Loss: 1.1514523680057505 | Accuracy:0.612\n",
      "1820/10000 iterations done. At i=1820 => | Loss: 1.0582150894002598 | Accuracy:0.608\n",
      "1840/10000 iterations done. At i=1840 => | Loss: 1.0608214907714304 | Accuracy:0.664\n",
      "1860/10000 iterations done. At i=1860 => | Loss: 1.0350183068662304 | Accuracy:0.668\n",
      "1880/10000 iterations done. At i=1880 => | Loss: 1.0275025083892868 | Accuracy:0.624\n",
      "1900/10000 iterations done. At i=1900 => | Loss: 1.0617775597743135 | Accuracy:0.648\n",
      "1920/10000 iterations done. At i=1920 => | Loss: 1.1315072180313026 | Accuracy:0.62\n",
      "1940/10000 iterations done. At i=1940 => | Loss: 0.9162792447254422 | Accuracy:0.672\n",
      "1960/10000 iterations done. At i=1960 => | Loss: 1.0250067514052836 | Accuracy:0.66\n",
      "1980/10000 iterations done. At i=1980 => | Loss: 1.0653371268872354 | Accuracy:0.616\n",
      "2000/10000 iterations done. At i=2000 => | Loss: 0.8660755757363398 | Accuracy:0.696\n",
      "2020/10000 iterations done. At i=2020 => | Loss: 1.15444334305276 | Accuracy:0.592\n",
      "2040/10000 iterations done. At i=2040 => | Loss: 0.9671381238891535 | Accuracy:0.672\n",
      "2060/10000 iterations done. At i=2060 => | Loss: 0.8881535815305512 | Accuracy:0.712\n",
      "2080/10000 iterations done. At i=2080 => | Loss: 1.0722669865273216 | Accuracy:0.636\n",
      "2100/10000 iterations done. At i=2100 => | Loss: 1.0410693383567526 | Accuracy:0.656\n",
      "2120/10000 iterations done. At i=2120 => | Loss: 1.1864779345417111 | Accuracy:0.644\n",
      "2140/10000 iterations done. At i=2140 => | Loss: 1.0465784543347831 | Accuracy:0.664\n",
      "2160/10000 iterations done. At i=2160 => | Loss: 0.8426369872902696 | Accuracy:0.724\n",
      "2180/10000 iterations done. At i=2180 => | Loss: 0.8797628712699521 | Accuracy:0.7\n",
      "2200/10000 iterations done. At i=2200 => | Loss: 0.9551011673529514 | Accuracy:0.64\n",
      "2220/10000 iterations done. At i=2220 => | Loss: 0.9683650150506318 | Accuracy:0.652\n",
      "2240/10000 iterations done. At i=2240 => | Loss: 0.8826633071887217 | Accuracy:0.668\n",
      "2260/10000 iterations done. At i=2260 => | Loss: 1.0883672729934737 | Accuracy:0.668\n",
      "2280/10000 iterations done. At i=2280 => | Loss: 0.9357427035719809 | Accuracy:0.68\n",
      "2300/10000 iterations done. At i=2300 => | Loss: 0.8890402093489891 | Accuracy:0.708\n",
      "2320/10000 iterations done. At i=2320 => | Loss: 0.9100479658236825 | Accuracy:0.692\n",
      "2340/10000 iterations done. At i=2340 => | Loss: 0.913205701677263 | Accuracy:0.664\n",
      "2360/10000 iterations done. At i=2360 => | Loss: 0.9184938358181912 | Accuracy:0.672\n",
      "2380/10000 iterations done. At i=2380 => | Loss: 1.0087550473062388 | Accuracy:0.664\n",
      "2400/10000 iterations done. At i=2400 => | Loss: 0.8682561752893543 | Accuracy:0.688\n",
      "2420/10000 iterations done. At i=2420 => | Loss: 0.7601199557633983 | Accuracy:0.748\n",
      "2440/10000 iterations done. At i=2440 => | Loss: 0.9602628141097249 | Accuracy:0.652\n",
      "2460/10000 iterations done. At i=2460 => | Loss: 0.9621665629975811 | Accuracy:0.664\n",
      "2480/10000 iterations done. At i=2480 => | Loss: 0.7970183522579851 | Accuracy:0.72\n",
      "2500/10000 iterations done. At i=2500 => | Loss: 0.94910276418899 | Accuracy:0.676\n",
      "2520/10000 iterations done. At i=2520 => | Loss: 0.8911748252801178 | Accuracy:0.688\n",
      "2540/10000 iterations done. At i=2540 => | Loss: 0.990360769135225 | Accuracy:0.708\n",
      "2560/10000 iterations done. At i=2560 => | Loss: 0.8266949818020721 | Accuracy:0.708\n",
      "2580/10000 iterations done. At i=2580 => | Loss: 0.8410116587006626 | Accuracy:0.708\n",
      "2600/10000 iterations done. At i=2600 => | Loss: 0.8404215058307609 | Accuracy:0.692\n",
      "2620/10000 iterations done. At i=2620 => | Loss: 0.8490127353699797 | Accuracy:0.692\n",
      "2640/10000 iterations done. At i=2640 => | Loss: 0.9600355925359854 | Accuracy:0.668\n",
      "2660/10000 iterations done. At i=2660 => | Loss: 1.2307225513101197 | Accuracy:0.564\n",
      "2680/10000 iterations done. At i=2680 => | Loss: 0.9111345941393594 | Accuracy:0.676\n",
      "2700/10000 iterations done. At i=2700 => | Loss: 0.8423568249651444 | Accuracy:0.744\n",
      "2720/10000 iterations done. At i=2720 => | Loss: 0.7495176405688276 | Accuracy:0.74\n",
      "2740/10000 iterations done. At i=2740 => | Loss: 0.8986168778512208 | Accuracy:0.656\n",
      "2760/10000 iterations done. At i=2760 => | Loss: 0.8112579933254258 | Accuracy:0.708\n",
      "2780/10000 iterations done. At i=2780 => | Loss: 0.7323111237475121 | Accuracy:0.756\n",
      "2800/10000 iterations done. At i=2800 => | Loss: 0.7065925074157094 | Accuracy:0.744\n",
      "2820/10000 iterations done. At i=2820 => | Loss: 0.74984881152348 | Accuracy:0.752\n",
      "2840/10000 iterations done. At i=2840 => | Loss: 0.9181068689161129 | Accuracy:0.712\n",
      "2860/10000 iterations done. At i=2860 => | Loss: 0.7106812228693611 | Accuracy:0.736\n",
      "2880/10000 iterations done. At i=2880 => | Loss: 0.6690280528900885 | Accuracy:0.768\n",
      "2900/10000 iterations done. At i=2900 => | Loss: 0.6415741903265568 | Accuracy:0.788\n",
      "2920/10000 iterations done. At i=2920 => | Loss: 0.8336234021876939 | Accuracy:0.688\n",
      "2940/10000 iterations done. At i=2940 => | Loss: 0.8618539003924592 | Accuracy:0.7\n",
      "2960/10000 iterations done. At i=2960 => | Loss: 0.857159332646922 | Accuracy:0.708\n",
      "2980/10000 iterations done. At i=2980 => | Loss: 0.8138418775117275 | Accuracy:0.736\n",
      "3000/10000 iterations done. At i=3000 => | Loss: 0.6734793349618751 | Accuracy:0.744\n",
      "3020/10000 iterations done. At i=3020 => | Loss: 0.8138983127677928 | Accuracy:0.676\n",
      "3040/10000 iterations done. At i=3040 => | Loss: 0.8499490969994012 | Accuracy:0.704\n",
      "3060/10000 iterations done. At i=3060 => | Loss: 0.6036242653456142 | Accuracy:0.808\n",
      "3080/10000 iterations done. At i=3080 => | Loss: 0.8254459208845252 | Accuracy:0.716\n",
      "3100/10000 iterations done. At i=3100 => | Loss: 0.7526674941701003 | Accuracy:0.748\n",
      "3120/10000 iterations done. At i=3120 => | Loss: 0.5790561411798619 | Accuracy:0.8\n",
      "3140/10000 iterations done. At i=3140 => | Loss: 0.7302336646819038 | Accuracy:0.756\n",
      "3160/10000 iterations done. At i=3160 => | Loss: 0.6657114750974529 | Accuracy:0.764\n",
      "3180/10000 iterations done. At i=3180 => | Loss: 0.8647657502962302 | Accuracy:0.716\n",
      "3200/10000 iterations done. At i=3200 => | Loss: 0.6586440474051165 | Accuracy:0.768\n",
      "3220/10000 iterations done. At i=3220 => | Loss: 0.6638974440333605 | Accuracy:0.76\n",
      "3240/10000 iterations done. At i=3240 => | Loss: 0.6524752846422068 | Accuracy:0.792\n",
      "3260/10000 iterations done. At i=3260 => | Loss: 0.6449363356478166 | Accuracy:0.776\n",
      "3280/10000 iterations done. At i=3280 => | Loss: 0.6759049653733462 | Accuracy:0.752\n",
      "3300/10000 iterations done. At i=3300 => | Loss: 0.6484269553805482 | Accuracy:0.796\n",
      "3320/10000 iterations done. At i=3320 => | Loss: 0.7410223000020135 | Accuracy:0.724\n",
      "3340/10000 iterations done. At i=3340 => | Loss: 0.8438127198109902 | Accuracy:0.692\n",
      "3360/10000 iterations done. At i=3360 => | Loss: 0.6919404182582191 | Accuracy:0.752\n",
      "3380/10000 iterations done. At i=3380 => | Loss: 0.6322623925959705 | Accuracy:0.756\n",
      "3400/10000 iterations done. At i=3400 => | Loss: 0.5641427643898191 | Accuracy:0.792\n",
      "3420/10000 iterations done. At i=3420 => | Loss: 0.6412467089001936 | Accuracy:0.78\n",
      "3440/10000 iterations done. At i=3440 => | Loss: 0.7073609614764734 | Accuracy:0.748\n",
      "3460/10000 iterations done. At i=3460 => | Loss: 0.5994530100395254 | Accuracy:0.788\n",
      "3480/10000 iterations done. At i=3480 => | Loss: 0.6099220993086288 | Accuracy:0.792\n",
      "3500/10000 iterations done. At i=3500 => | Loss: 0.6770266704164851 | Accuracy:0.768\n",
      "3520/10000 iterations done. At i=3520 => | Loss: 0.7227463203902521 | Accuracy:0.76\n",
      "3540/10000 iterations done. At i=3540 => | Loss: 0.7608224393215359 | Accuracy:0.748\n",
      "3560/10000 iterations done. At i=3560 => | Loss: 0.5948521096990887 | Accuracy:0.796\n",
      "3580/10000 iterations done. At i=3580 => | Loss: 0.6472332509625096 | Accuracy:0.764\n",
      "3600/10000 iterations done. At i=3600 => | Loss: 0.5673038033101406 | Accuracy:0.816\n",
      "3620/10000 iterations done. At i=3620 => | Loss: 0.7178676387206469 | Accuracy:0.776\n",
      "3640/10000 iterations done. At i=3640 => | Loss: 0.5332244160065561 | Accuracy:0.828\n",
      "3660/10000 iterations done. At i=3660 => | Loss: 0.6511423643261511 | Accuracy:0.784\n",
      "3680/10000 iterations done. At i=3680 => | Loss: 0.5210938161026802 | Accuracy:0.848\n",
      "3700/10000 iterations done. At i=3700 => | Loss: 0.4088442030172008 | Accuracy:0.86\n",
      "3720/10000 iterations done. At i=3720 => | Loss: 0.4949066135766327 | Accuracy:0.804\n",
      "3740/10000 iterations done. At i=3740 => | Loss: 0.6116667042718305 | Accuracy:0.788\n",
      "3760/10000 iterations done. At i=3760 => | Loss: 0.455083628755934 | Accuracy:0.86\n",
      "3780/10000 iterations done. At i=3780 => | Loss: 0.7299789120275268 | Accuracy:0.752\n",
      "3800/10000 iterations done. At i=3800 => | Loss: 0.48049354046337045 | Accuracy:0.856\n",
      "3820/10000 iterations done. At i=3820 => | Loss: 0.5033537176168054 | Accuracy:0.816\n",
      "3840/10000 iterations done. At i=3840 => | Loss: 0.7227483553325812 | Accuracy:0.784\n",
      "3860/10000 iterations done. At i=3860 => | Loss: 0.5918657148739161 | Accuracy:0.796\n",
      "3880/10000 iterations done. At i=3880 => | Loss: 0.4403050107043547 | Accuracy:0.856\n",
      "3900/10000 iterations done. At i=3900 => | Loss: 0.4593095167420377 | Accuracy:0.86\n",
      "3920/10000 iterations done. At i=3920 => | Loss: 0.6245990253593254 | Accuracy:0.8\n",
      "3940/10000 iterations done. At i=3940 => | Loss: 0.5717300826479145 | Accuracy:0.812\n",
      "3960/10000 iterations done. At i=3960 => | Loss: 0.556947296094607 | Accuracy:0.816\n",
      "3980/10000 iterations done. At i=3980 => | Loss: 0.5590723569558487 | Accuracy:0.812\n",
      "4000/10000 iterations done. At i=4000 => | Loss: 0.5917882022265123 | Accuracy:0.78\n",
      "4020/10000 iterations done. At i=4020 => | Loss: 0.5034040543398116 | Accuracy:0.824\n",
      "4040/10000 iterations done. At i=4040 => | Loss: 0.563661150673513 | Accuracy:0.812\n",
      "4060/10000 iterations done. At i=4060 => | Loss: 0.5374796761410596 | Accuracy:0.824\n",
      "4080/10000 iterations done. At i=4080 => | Loss: 0.6397005771203182 | Accuracy:0.764\n",
      "4100/10000 iterations done. At i=4100 => | Loss: 0.5714368626969875 | Accuracy:0.816\n",
      "4120/10000 iterations done. At i=4120 => | Loss: 0.44830992686773447 | Accuracy:0.84\n",
      "4140/10000 iterations done. At i=4140 => | Loss: 0.6038280821958617 | Accuracy:0.772\n",
      "4160/10000 iterations done. At i=4160 => | Loss: 0.5357136122762993 | Accuracy:0.804\n",
      "4180/10000 iterations done. At i=4180 => | Loss: 0.5750455725004563 | Accuracy:0.8\n",
      "4200/10000 iterations done. At i=4200 => | Loss: 0.7226028029064516 | Accuracy:0.74\n",
      "4220/10000 iterations done. At i=4220 => | Loss: 0.4296655405099559 | Accuracy:0.852\n",
      "4240/10000 iterations done. At i=4240 => | Loss: 0.5307491739512583 | Accuracy:0.824\n",
      "4260/10000 iterations done. At i=4260 => | Loss: 0.46039378226324 | Accuracy:0.84\n",
      "4280/10000 iterations done. At i=4280 => | Loss: 0.509530022307602 | Accuracy:0.832\n",
      "4300/10000 iterations done. At i=4300 => | Loss: 0.4924185381186293 | Accuracy:0.804\n",
      "4320/10000 iterations done. At i=4320 => | Loss: 0.49914002957314674 | Accuracy:0.824\n",
      "4340/10000 iterations done. At i=4340 => | Loss: 0.4355915474268751 | Accuracy:0.84\n",
      "4360/10000 iterations done. At i=4360 => | Loss: 0.3505667488597595 | Accuracy:0.892\n",
      "4380/10000 iterations done. At i=4380 => | Loss: 0.5363511534828603 | Accuracy:0.828\n",
      "4400/10000 iterations done. At i=4400 => | Loss: 0.4857148353774089 | Accuracy:0.852\n",
      "4420/10000 iterations done. At i=4420 => | Loss: 0.4145141768383277 | Accuracy:0.844\n",
      "4440/10000 iterations done. At i=4440 => | Loss: 0.42094669728855455 | Accuracy:0.864\n",
      "4460/10000 iterations done. At i=4460 => | Loss: 0.43611601827876156 | Accuracy:0.852\n",
      "4480/10000 iterations done. At i=4480 => | Loss: 0.511900146024537 | Accuracy:0.836\n",
      "4500/10000 iterations done. At i=4500 => | Loss: 0.44446012551123887 | Accuracy:0.832\n",
      "4520/10000 iterations done. At i=4520 => | Loss: 0.4088321109201025 | Accuracy:0.848\n",
      "4540/10000 iterations done. At i=4540 => | Loss: 0.3332514002438212 | Accuracy:0.856\n",
      "4560/10000 iterations done. At i=4560 => | Loss: 0.43395165011691744 | Accuracy:0.856\n",
      "4580/10000 iterations done. At i=4580 => | Loss: 0.3727795683395093 | Accuracy:0.868\n",
      "4600/10000 iterations done. At i=4600 => | Loss: 0.4283976900756012 | Accuracy:0.848\n",
      "4620/10000 iterations done. At i=4620 => | Loss: 0.4865330846432674 | Accuracy:0.84\n",
      "4640/10000 iterations done. At i=4640 => | Loss: 0.3924774847439859 | Accuracy:0.848\n",
      "4660/10000 iterations done. At i=4660 => | Loss: 0.36605707988501474 | Accuracy:0.86\n",
      "4680/10000 iterations done. At i=4680 => | Loss: 0.48439875465269105 | Accuracy:0.848\n",
      "4700/10000 iterations done. At i=4700 => | Loss: 0.29786015083476985 | Accuracy:0.912\n",
      "4720/10000 iterations done. At i=4720 => | Loss: 0.4414562306268167 | Accuracy:0.828\n",
      "4740/10000 iterations done. At i=4740 => | Loss: 0.36452281696490196 | Accuracy:0.868\n",
      "4760/10000 iterations done. At i=4760 => | Loss: 0.570396579180837 | Accuracy:0.792\n",
      "4780/10000 iterations done. At i=4780 => | Loss: 0.36988154237585014 | Accuracy:0.868\n",
      "4800/10000 iterations done. At i=4800 => | Loss: 0.3691870103348035 | Accuracy:0.884\n",
      "4820/10000 iterations done. At i=4820 => | Loss: 0.4765983534122689 | Accuracy:0.856\n",
      "4840/10000 iterations done. At i=4840 => | Loss: 0.3856085874671934 | Accuracy:0.872\n",
      "4860/10000 iterations done. At i=4860 => | Loss: 0.5580514058432493 | Accuracy:0.812\n",
      "4880/10000 iterations done. At i=4880 => | Loss: 0.40735363080996523 | Accuracy:0.856\n",
      "4900/10000 iterations done. At i=4900 => | Loss: 0.3670667938072129 | Accuracy:0.872\n",
      "4920/10000 iterations done. At i=4920 => | Loss: 0.45444418003693043 | Accuracy:0.86\n",
      "4940/10000 iterations done. At i=4940 => | Loss: 0.4736155816738008 | Accuracy:0.852\n",
      "4960/10000 iterations done. At i=4960 => | Loss: 0.3352532983321748 | Accuracy:0.88\n",
      "4980/10000 iterations done. At i=4980 => | Loss: 0.409926776331219 | Accuracy:0.88\n",
      "5000/10000 iterations done. At i=5000 => | Loss: 0.35969384060035264 | Accuracy:0.888\n",
      "5020/10000 iterations done. At i=5020 => | Loss: 0.32639153577908164 | Accuracy:0.876\n",
      "5040/10000 iterations done. At i=5040 => | Loss: 0.5107025741464967 | Accuracy:0.812\n",
      "5060/10000 iterations done. At i=5060 => | Loss: 0.39988232340637603 | Accuracy:0.852\n",
      "5080/10000 iterations done. At i=5080 => | Loss: 0.3227056763254713 | Accuracy:0.884\n",
      "5100/10000 iterations done. At i=5100 => | Loss: 0.2761970490265879 | Accuracy:0.912\n",
      "5120/10000 iterations done. At i=5120 => | Loss: 0.35465166232592277 | Accuracy:0.892\n",
      "5140/10000 iterations done. At i=5140 => | Loss: 0.4062396245005226 | Accuracy:0.876\n",
      "5160/10000 iterations done. At i=5160 => | Loss: 0.3583985454612937 | Accuracy:0.884\n",
      "5180/10000 iterations done. At i=5180 => | Loss: 0.2745825781765592 | Accuracy:0.92\n",
      "5200/10000 iterations done. At i=5200 => | Loss: 0.3060974858326157 | Accuracy:0.88\n",
      "5220/10000 iterations done. At i=5220 => | Loss: 0.364492526961042 | Accuracy:0.88\n",
      "5240/10000 iterations done. At i=5240 => | Loss: 0.40011512262020693 | Accuracy:0.864\n",
      "5260/10000 iterations done. At i=5260 => | Loss: 0.39598870026053373 | Accuracy:0.876\n",
      "5280/10000 iterations done. At i=5280 => | Loss: 0.3725196829732646 | Accuracy:0.88\n",
      "5300/10000 iterations done. At i=5300 => | Loss: 0.4417131414095048 | Accuracy:0.872\n",
      "5320/10000 iterations done. At i=5320 => | Loss: 0.32527089446139085 | Accuracy:0.888\n",
      "5340/10000 iterations done. At i=5340 => | Loss: 0.6146312942205518 | Accuracy:0.772\n",
      "5360/10000 iterations done. At i=5360 => | Loss: 0.37419288200229767 | Accuracy:0.876\n",
      "5380/10000 iterations done. At i=5380 => | Loss: 0.42057526180178867 | Accuracy:0.848\n",
      "5400/10000 iterations done. At i=5400 => | Loss: 0.3964621045617345 | Accuracy:0.848\n",
      "5420/10000 iterations done. At i=5420 => | Loss: 0.5528334272728287 | Accuracy:0.816\n",
      "5440/10000 iterations done. At i=5440 => | Loss: 0.5009426242105381 | Accuracy:0.84\n",
      "5460/10000 iterations done. At i=5460 => | Loss: 0.3152242431051633 | Accuracy:0.904\n",
      "5480/10000 iterations done. At i=5480 => | Loss: 0.40670723827559924 | Accuracy:0.86\n",
      "5500/10000 iterations done. At i=5500 => | Loss: 0.3943013359976815 | Accuracy:0.864\n",
      "5520/10000 iterations done. At i=5520 => | Loss: 0.2502636009190946 | Accuracy:0.912\n",
      "5540/10000 iterations done. At i=5540 => | Loss: 0.3325139209751261 | Accuracy:0.9\n",
      "5560/10000 iterations done. At i=5560 => | Loss: 0.2920582884936309 | Accuracy:0.884\n",
      "5580/10000 iterations done. At i=5580 => | Loss: 0.32623898258425255 | Accuracy:0.872\n",
      "5600/10000 iterations done. At i=5600 => | Loss: 0.3738196482087567 | Accuracy:0.872\n",
      "5620/10000 iterations done. At i=5620 => | Loss: 0.39121273621158836 | Accuracy:0.84\n",
      "5640/10000 iterations done. At i=5640 => | Loss: 0.31266794783734236 | Accuracy:0.9\n",
      "5660/10000 iterations done. At i=5660 => | Loss: 0.3523823403572694 | Accuracy:0.852\n",
      "5680/10000 iterations done. At i=5680 => | Loss: 0.22363006593598123 | Accuracy:0.912\n",
      "5700/10000 iterations done. At i=5700 => | Loss: 0.2953413001133122 | Accuracy:0.888\n",
      "5720/10000 iterations done. At i=5720 => | Loss: 0.33867116567165156 | Accuracy:0.892\n",
      "5740/10000 iterations done. At i=5740 => | Loss: 0.2885354352234094 | Accuracy:0.904\n",
      "5760/10000 iterations done. At i=5760 => | Loss: 0.33928599188942155 | Accuracy:0.88\n",
      "5780/10000 iterations done. At i=5780 => | Loss: 0.270425724774074 | Accuracy:0.916\n",
      "5800/10000 iterations done. At i=5800 => | Loss: 0.2563187453292984 | Accuracy:0.916\n",
      "5820/10000 iterations done. At i=5820 => | Loss: 0.19223957519761065 | Accuracy:0.928\n",
      "5840/10000 iterations done. At i=5840 => | Loss: 0.3209487340991809 | Accuracy:0.912\n",
      "5860/10000 iterations done. At i=5860 => | Loss: 0.3109019212240179 | Accuracy:0.9\n",
      "5880/10000 iterations done. At i=5880 => | Loss: 0.20199591970437486 | Accuracy:0.936\n",
      "5900/10000 iterations done. At i=5900 => | Loss: 0.31513178064454 | Accuracy:0.88\n",
      "5920/10000 iterations done. At i=5920 => | Loss: 0.2693164149429779 | Accuracy:0.904\n",
      "5940/10000 iterations done. At i=5940 => | Loss: 0.24087926700869125 | Accuracy:0.928\n",
      "5960/10000 iterations done. At i=5960 => | Loss: 0.2736634733590739 | Accuracy:0.904\n",
      "5980/10000 iterations done. At i=5980 => | Loss: 0.26422617794130826 | Accuracy:0.92\n",
      "6000/10000 iterations done. At i=6000 => | Loss: 0.2063501149008867 | Accuracy:0.924\n",
      "6020/10000 iterations done. At i=6020 => | Loss: 0.32248261493001024 | Accuracy:0.896\n",
      "6040/10000 iterations done. At i=6040 => | Loss: 0.2914192044274354 | Accuracy:0.876\n",
      "6060/10000 iterations done. At i=6060 => | Loss: 0.30259259682551604 | Accuracy:0.916\n",
      "6080/10000 iterations done. At i=6080 => | Loss: 0.27229223681540293 | Accuracy:0.904\n",
      "6100/10000 iterations done. At i=6100 => | Loss: 0.2488305891705636 | Accuracy:0.912\n",
      "6120/10000 iterations done. At i=6120 => | Loss: 0.34230091145304564 | Accuracy:0.884\n",
      "6140/10000 iterations done. At i=6140 => | Loss: 0.373993082043577 | Accuracy:0.896\n",
      "6160/10000 iterations done. At i=6160 => | Loss: 0.23299746407686514 | Accuracy:0.916\n",
      "6180/10000 iterations done. At i=6180 => | Loss: 0.22966172777087626 | Accuracy:0.912\n",
      "6200/10000 iterations done. At i=6200 => | Loss: 0.31556983532553484 | Accuracy:0.892\n",
      "6220/10000 iterations done. At i=6220 => | Loss: 0.17094739407698784 | Accuracy:0.92\n",
      "6240/10000 iterations done. At i=6240 => | Loss: 0.3106007531748578 | Accuracy:0.896\n",
      "6260/10000 iterations done. At i=6260 => | Loss: 0.22528848709318713 | Accuracy:0.916\n",
      "6280/10000 iterations done. At i=6280 => | Loss: 0.23944481540360363 | Accuracy:0.924\n",
      "6300/10000 iterations done. At i=6300 => | Loss: 0.28270604389471077 | Accuracy:0.892\n",
      "6320/10000 iterations done. At i=6320 => | Loss: 0.33159736207102347 | Accuracy:0.884\n",
      "6340/10000 iterations done. At i=6340 => | Loss: 0.27928719008934794 | Accuracy:0.888\n",
      "6360/10000 iterations done. At i=6360 => | Loss: 0.24932655272638732 | Accuracy:0.912\n",
      "6380/10000 iterations done. At i=6380 => | Loss: 0.24592589482773114 | Accuracy:0.904\n",
      "6400/10000 iterations done. At i=6400 => | Loss: 0.2855333709641585 | Accuracy:0.904\n",
      "6420/10000 iterations done. At i=6420 => | Loss: 0.3052838822520961 | Accuracy:0.92\n",
      "6440/10000 iterations done. At i=6440 => | Loss: 0.19671559898973737 | Accuracy:0.924\n",
      "6460/10000 iterations done. At i=6460 => | Loss: 0.28457434798491665 | Accuracy:0.916\n",
      "6480/10000 iterations done. At i=6480 => | Loss: 0.21729555321795926 | Accuracy:0.912\n",
      "6500/10000 iterations done. At i=6500 => | Loss: 0.23156152144957204 | Accuracy:0.936\n",
      "6520/10000 iterations done. At i=6520 => | Loss: 0.19913935573679856 | Accuracy:0.928\n",
      "6540/10000 iterations done. At i=6540 => | Loss: 0.2699152533259249 | Accuracy:0.908\n",
      "6560/10000 iterations done. At i=6560 => | Loss: 0.17539036516075415 | Accuracy:0.94\n",
      "6580/10000 iterations done. At i=6580 => | Loss: 0.27050406749777384 | Accuracy:0.908\n",
      "6600/10000 iterations done. At i=6600 => | Loss: 0.21672663128763187 | Accuracy:0.896\n",
      "6620/10000 iterations done. At i=6620 => | Loss: 0.19118479299417515 | Accuracy:0.94\n",
      "6640/10000 iterations done. At i=6640 => | Loss: 0.23395333839926918 | Accuracy:0.932\n",
      "6660/10000 iterations done. At i=6660 => | Loss: 0.2719517863678725 | Accuracy:0.892\n",
      "6680/10000 iterations done. At i=6680 => | Loss: 0.18979621522080503 | Accuracy:0.928\n",
      "6700/10000 iterations done. At i=6700 => | Loss: 0.24741608093927225 | Accuracy:0.908\n",
      "6720/10000 iterations done. At i=6720 => | Loss: 0.2368031471807384 | Accuracy:0.928\n",
      "6740/10000 iterations done. At i=6740 => | Loss: 0.18578127812883774 | Accuracy:0.94\n",
      "6760/10000 iterations done. At i=6760 => | Loss: 0.173521389219899 | Accuracy:0.94\n",
      "6780/10000 iterations done. At i=6780 => | Loss: 0.16460464170577377 | Accuracy:0.944\n",
      "6800/10000 iterations done. At i=6800 => | Loss: 0.19272578896056883 | Accuracy:0.916\n",
      "6820/10000 iterations done. At i=6820 => | Loss: 0.20396466489371307 | Accuracy:0.944\n",
      "6840/10000 iterations done. At i=6840 => | Loss: 0.1465504260779262 | Accuracy:0.956\n",
      "6860/10000 iterations done. At i=6860 => | Loss: 0.1864017511269729 | Accuracy:0.932\n",
      "6880/10000 iterations done. At i=6880 => | Loss: 0.17882765885423724 | Accuracy:0.94\n",
      "6900/10000 iterations done. At i=6900 => | Loss: 0.22558185137575323 | Accuracy:0.916\n",
      "6920/10000 iterations done. At i=6920 => | Loss: 0.20454945297621863 | Accuracy:0.94\n",
      "6940/10000 iterations done. At i=6940 => | Loss: 0.24504109605006946 | Accuracy:0.936\n",
      "6960/10000 iterations done. At i=6960 => | Loss: 0.22150352790764738 | Accuracy:0.92\n",
      "6980/10000 iterations done. At i=6980 => | Loss: 0.17814449342835945 | Accuracy:0.94\n",
      "7000/10000 iterations done. At i=7000 => | Loss: 0.2385614501968871 | Accuracy:0.92\n",
      "7020/10000 iterations done. At i=7020 => | Loss: 0.14281950107012858 | Accuracy:0.96\n",
      "7040/10000 iterations done. At i=7040 => | Loss: 0.15145383041913907 | Accuracy:0.944\n",
      "7060/10000 iterations done. At i=7060 => | Loss: 0.18517348848281914 | Accuracy:0.94\n",
      "7080/10000 iterations done. At i=7080 => | Loss: 0.21136313003179008 | Accuracy:0.936\n",
      "7100/10000 iterations done. At i=7100 => | Loss: 0.15661314808830204 | Accuracy:0.944\n",
      "7120/10000 iterations done. At i=7120 => | Loss: 0.21659721136078572 | Accuracy:0.92\n",
      "7140/10000 iterations done. At i=7140 => | Loss: 0.1854868913577878 | Accuracy:0.932\n",
      "7160/10000 iterations done. At i=7160 => | Loss: 0.23092509095361027 | Accuracy:0.936\n",
      "7180/10000 iterations done. At i=7180 => | Loss: 0.1479049118481161 | Accuracy:0.952\n",
      "7200/10000 iterations done. At i=7200 => | Loss: 0.14730244969252998 | Accuracy:0.956\n",
      "7220/10000 iterations done. At i=7220 => | Loss: 0.13889001832482928 | Accuracy:0.952\n",
      "7240/10000 iterations done. At i=7240 => | Loss: 0.15172609765565728 | Accuracy:0.952\n",
      "7260/10000 iterations done. At i=7260 => | Loss: 0.1983849027538201 | Accuracy:0.924\n",
      "7280/10000 iterations done. At i=7280 => | Loss: 0.2891479519017997 | Accuracy:0.924\n",
      "7300/10000 iterations done. At i=7300 => | Loss: 0.226692639214615 | Accuracy:0.916\n",
      "7320/10000 iterations done. At i=7320 => | Loss: 0.13514893361800878 | Accuracy:0.952\n",
      "7340/10000 iterations done. At i=7340 => | Loss: 0.16754839665358273 | Accuracy:0.936\n",
      "7360/10000 iterations done. At i=7360 => | Loss: 0.18009276571684882 | Accuracy:0.94\n",
      "7380/10000 iterations done. At i=7380 => | Loss: 0.24217055987273978 | Accuracy:0.912\n",
      "7400/10000 iterations done. At i=7400 => | Loss: 0.21449091318065888 | Accuracy:0.92\n",
      "7420/10000 iterations done. At i=7420 => | Loss: 0.1429788748658559 | Accuracy:0.952\n",
      "7440/10000 iterations done. At i=7440 => | Loss: 0.28221833242485805 | Accuracy:0.916\n",
      "7460/10000 iterations done. At i=7460 => | Loss: 0.16667933972646973 | Accuracy:0.956\n",
      "7480/10000 iterations done. At i=7480 => | Loss: 0.12245882550382137 | Accuracy:0.964\n",
      "7500/10000 iterations done. At i=7500 => | Loss: 0.22476805665095578 | Accuracy:0.936\n",
      "7520/10000 iterations done. At i=7520 => | Loss: 0.2157919477645728 | Accuracy:0.932\n",
      "7540/10000 iterations done. At i=7540 => | Loss: 0.17619542881782665 | Accuracy:0.94\n",
      "7560/10000 iterations done. At i=7560 => | Loss: 0.23065243382140146 | Accuracy:0.92\n",
      "7580/10000 iterations done. At i=7580 => | Loss: 0.19217407910118448 | Accuracy:0.932\n",
      "7600/10000 iterations done. At i=7600 => | Loss: 0.19143105377526398 | Accuracy:0.924\n",
      "7620/10000 iterations done. At i=7620 => | Loss: 0.16856212501499324 | Accuracy:0.932\n",
      "7640/10000 iterations done. At i=7640 => | Loss: 0.27071210350928365 | Accuracy:0.924\n",
      "7660/10000 iterations done. At i=7660 => | Loss: 0.17635333039247597 | Accuracy:0.936\n",
      "7680/10000 iterations done. At i=7680 => | Loss: 0.2397651087171746 | Accuracy:0.92\n",
      "7700/10000 iterations done. At i=7700 => | Loss: 0.12565929812223403 | Accuracy:0.968\n",
      "7720/10000 iterations done. At i=7720 => | Loss: 0.20067309842512748 | Accuracy:0.936\n",
      "7740/10000 iterations done. At i=7740 => | Loss: 0.19444698095154542 | Accuracy:0.932\n",
      "7760/10000 iterations done. At i=7760 => | Loss: 0.11981326765645826 | Accuracy:0.956\n",
      "7780/10000 iterations done. At i=7780 => | Loss: 0.21624889740157713 | Accuracy:0.924\n",
      "7800/10000 iterations done. At i=7800 => | Loss: 0.19624658616262003 | Accuracy:0.916\n",
      "7820/10000 iterations done. At i=7820 => | Loss: 0.1339314393111491 | Accuracy:0.952\n",
      "7840/10000 iterations done. At i=7840 => | Loss: 0.15761332908926443 | Accuracy:0.944\n",
      "7860/10000 iterations done. At i=7860 => | Loss: 0.1492849838290444 | Accuracy:0.948\n",
      "7880/10000 iterations done. At i=7880 => | Loss: 0.17286742071030917 | Accuracy:0.936\n",
      "7900/10000 iterations done. At i=7900 => | Loss: 0.21339271267232293 | Accuracy:0.924\n",
      "7920/10000 iterations done. At i=7920 => | Loss: 0.15650821138813079 | Accuracy:0.936\n",
      "7940/10000 iterations done. At i=7940 => | Loss: 0.14780856236879675 | Accuracy:0.94\n",
      "7960/10000 iterations done. At i=7960 => | Loss: 0.24507521611775332 | Accuracy:0.904\n",
      "7980/10000 iterations done. At i=7980 => | Loss: 0.13944940507653547 | Accuracy:0.932\n",
      "8000/10000 iterations done. At i=8000 => | Loss: 0.18563521430121308 | Accuracy:0.936\n",
      "8020/10000 iterations done. At i=8020 => | Loss: 0.11690482577781275 | Accuracy:0.976\n",
      "8040/10000 iterations done. At i=8040 => | Loss: 0.17709211204974723 | Accuracy:0.932\n",
      "8060/10000 iterations done. At i=8060 => | Loss: 0.0971500639527161 | Accuracy:0.968\n",
      "8080/10000 iterations done. At i=8080 => | Loss: 0.17647479305999525 | Accuracy:0.948\n",
      "8100/10000 iterations done. At i=8100 => | Loss: 0.10335396917183888 | Accuracy:0.964\n",
      "8120/10000 iterations done. At i=8120 => | Loss: 0.10910826913467564 | Accuracy:0.968\n",
      "8140/10000 iterations done. At i=8140 => | Loss: 0.13496157397056344 | Accuracy:0.96\n",
      "8160/10000 iterations done. At i=8160 => | Loss: 0.11581360192628938 | Accuracy:0.964\n",
      "8180/10000 iterations done. At i=8180 => | Loss: 0.17167966901271636 | Accuracy:0.948\n",
      "8200/10000 iterations done. At i=8200 => | Loss: 0.1492241370191881 | Accuracy:0.952\n",
      "8220/10000 iterations done. At i=8220 => | Loss: 0.11055906496034827 | Accuracy:0.956\n",
      "8240/10000 iterations done. At i=8240 => | Loss: 0.10940747271067851 | Accuracy:0.956\n",
      "8260/10000 iterations done. At i=8260 => | Loss: 0.18764452306213833 | Accuracy:0.924\n",
      "8280/10000 iterations done. At i=8280 => | Loss: 0.2064009039759488 | Accuracy:0.928\n",
      "8300/10000 iterations done. At i=8300 => | Loss: 0.16907371053140963 | Accuracy:0.944\n",
      "8320/10000 iterations done. At i=8320 => | Loss: 0.16856740415730667 | Accuracy:0.964\n",
      "8340/10000 iterations done. At i=8340 => | Loss: 0.10980596616061973 | Accuracy:0.968\n",
      "8360/10000 iterations done. At i=8360 => | Loss: 0.19718297579020086 | Accuracy:0.94\n",
      "8380/10000 iterations done. At i=8380 => | Loss: 0.11553855835174508 | Accuracy:0.972\n",
      "8400/10000 iterations done. At i=8400 => | Loss: 0.12171421249884751 | Accuracy:0.944\n",
      "8420/10000 iterations done. At i=8420 => | Loss: 0.0730719781216995 | Accuracy:0.98\n",
      "8440/10000 iterations done. At i=8440 => | Loss: 0.10391348884829221 | Accuracy:0.968\n",
      "8460/10000 iterations done. At i=8460 => | Loss: 0.17715886656328503 | Accuracy:0.952\n",
      "8480/10000 iterations done. At i=8480 => | Loss: 0.1262423217462986 | Accuracy:0.964\n",
      "8500/10000 iterations done. At i=8500 => | Loss: 0.1617575909956931 | Accuracy:0.932\n",
      "8520/10000 iterations done. At i=8520 => | Loss: 0.05851479727064852 | Accuracy:0.98\n",
      "8540/10000 iterations done. At i=8540 => | Loss: 0.11477927511880523 | Accuracy:0.968\n",
      "8560/10000 iterations done. At i=8560 => | Loss: 0.13619027907543815 | Accuracy:0.96\n",
      "8580/10000 iterations done. At i=8580 => | Loss: 0.1519749079762228 | Accuracy:0.944\n",
      "8600/10000 iterations done. At i=8600 => | Loss: 0.15264466402070265 | Accuracy:0.948\n",
      "8620/10000 iterations done. At i=8620 => | Loss: 0.08483086174741211 | Accuracy:0.984\n",
      "8640/10000 iterations done. At i=8640 => | Loss: 0.08603252117521916 | Accuracy:0.98\n",
      "8660/10000 iterations done. At i=8660 => | Loss: 0.08809533972545561 | Accuracy:0.96\n",
      "8680/10000 iterations done. At i=8680 => | Loss: 0.1304419138423029 | Accuracy:0.96\n",
      "8700/10000 iterations done. At i=8700 => | Loss: 0.09806810345769894 | Accuracy:0.956\n",
      "8720/10000 iterations done. At i=8720 => | Loss: 0.14919705686972046 | Accuracy:0.968\n",
      "8740/10000 iterations done. At i=8740 => | Loss: 0.15675025709250115 | Accuracy:0.948\n",
      "8760/10000 iterations done. At i=8760 => | Loss: 0.09007720961484914 | Accuracy:0.968\n",
      "8780/10000 iterations done. At i=8780 => | Loss: 0.09836888553070196 | Accuracy:0.972\n",
      "8800/10000 iterations done. At i=8800 => | Loss: 0.14325311476914393 | Accuracy:0.956\n",
      "8820/10000 iterations done. At i=8820 => | Loss: 0.12696253962976511 | Accuracy:0.96\n",
      "8840/10000 iterations done. At i=8840 => | Loss: 0.16361609705873842 | Accuracy:0.936\n",
      "8860/10000 iterations done. At i=8860 => | Loss: 0.0830256995848218 | Accuracy:0.968\n",
      "8880/10000 iterations done. At i=8880 => | Loss: 0.10899506326353099 | Accuracy:0.968\n",
      "8900/10000 iterations done. At i=8900 => | Loss: 0.07763938066366413 | Accuracy:0.972\n",
      "8920/10000 iterations done. At i=8920 => | Loss: 0.1287343459363044 | Accuracy:0.956\n",
      "8940/10000 iterations done. At i=8940 => | Loss: 0.07570190173932079 | Accuracy:0.972\n",
      "8960/10000 iterations done. At i=8960 => | Loss: 0.10849392227792728 | Accuracy:0.968\n",
      "8980/10000 iterations done. At i=8980 => | Loss: 0.121012268496883 | Accuracy:0.948\n",
      "9000/10000 iterations done. At i=9000 => | Loss: 0.12221795288353351 | Accuracy:0.952\n",
      "9020/10000 iterations done. At i=9020 => | Loss: 0.11692313972109725 | Accuracy:0.964\n",
      "9040/10000 iterations done. At i=9040 => | Loss: 0.052637145976009936 | Accuracy:0.976\n",
      "9060/10000 iterations done. At i=9060 => | Loss: 0.18408263039614364 | Accuracy:0.932\n",
      "9080/10000 iterations done. At i=9080 => | Loss: 0.09621459205064081 | Accuracy:0.964\n",
      "9100/10000 iterations done. At i=9100 => | Loss: 0.062446741059533045 | Accuracy:0.976\n",
      "9120/10000 iterations done. At i=9120 => | Loss: 0.10063282940665974 | Accuracy:0.964\n",
      "9140/10000 iterations done. At i=9140 => | Loss: 0.07133609817651136 | Accuracy:0.976\n",
      "9160/10000 iterations done. At i=9160 => | Loss: 0.06414447614259176 | Accuracy:0.98\n",
      "9180/10000 iterations done. At i=9180 => | Loss: 0.07582223519509808 | Accuracy:0.968\n",
      "9200/10000 iterations done. At i=9200 => | Loss: 0.08684551106516815 | Accuracy:0.972\n",
      "9220/10000 iterations done. At i=9220 => | Loss: 0.11634754800039951 | Accuracy:0.964\n",
      "9240/10000 iterations done. At i=9240 => | Loss: 0.2237289344823859 | Accuracy:0.924\n",
      "9260/10000 iterations done. At i=9260 => | Loss: 0.08293550156054298 | Accuracy:0.964\n",
      "9280/10000 iterations done. At i=9280 => | Loss: 0.12269426538448193 | Accuracy:0.968\n",
      "9300/10000 iterations done. At i=9300 => | Loss: 0.06316012377055732 | Accuracy:0.98\n",
      "9320/10000 iterations done. At i=9320 => | Loss: 0.22830316866497657 | Accuracy:0.936\n",
      "9340/10000 iterations done. At i=9340 => | Loss: 0.12070277288878685 | Accuracy:0.956\n",
      "9360/10000 iterations done. At i=9360 => | Loss: 0.10390624497649645 | Accuracy:0.952\n",
      "9380/10000 iterations done. At i=9380 => | Loss: 0.13496214796275322 | Accuracy:0.936\n",
      "9400/10000 iterations done. At i=9400 => | Loss: 0.08959130618798092 | Accuracy:0.972\n",
      "9420/10000 iterations done. At i=9420 => | Loss: 0.14262435888816744 | Accuracy:0.964\n",
      "9440/10000 iterations done. At i=9440 => | Loss: 0.0914528482104632 | Accuracy:0.98\n",
      "9460/10000 iterations done. At i=9460 => | Loss: 0.08961328144099925 | Accuracy:0.972\n",
      "9480/10000 iterations done. At i=9480 => | Loss: 0.06169637630795229 | Accuracy:0.984\n",
      "9500/10000 iterations done. At i=9500 => | Loss: 0.07556401295438106 | Accuracy:0.976\n",
      "9520/10000 iterations done. At i=9520 => | Loss: 0.20458410781071756 | Accuracy:0.928\n",
      "9540/10000 iterations done. At i=9540 => | Loss: 0.15483673069642453 | Accuracy:0.94\n",
      "9560/10000 iterations done. At i=9560 => | Loss: 0.08577048357472515 | Accuracy:0.976\n",
      "9580/10000 iterations done. At i=9580 => | Loss: 0.08973606001377041 | Accuracy:0.972\n",
      "9600/10000 iterations done. At i=9600 => | Loss: 0.10569846901036098 | Accuracy:0.96\n",
      "9620/10000 iterations done. At i=9620 => | Loss: 0.10306551010044014 | Accuracy:0.96\n",
      "9640/10000 iterations done. At i=9640 => | Loss: 0.1047698133240824 | Accuracy:0.952\n",
      "9660/10000 iterations done. At i=9660 => | Loss: 0.1481268948252219 | Accuracy:0.94\n",
      "9680/10000 iterations done. At i=9680 => | Loss: 0.11984824414698862 | Accuracy:0.968\n",
      "9700/10000 iterations done. At i=9700 => | Loss: 0.13026264917284783 | Accuracy:0.972\n",
      "9720/10000 iterations done. At i=9720 => | Loss: 0.06585488782641079 | Accuracy:0.98\n",
      "9740/10000 iterations done. At i=9740 => | Loss: 0.060203367446609105 | Accuracy:0.98\n",
      "9760/10000 iterations done. At i=9760 => | Loss: 0.06747093332510541 | Accuracy:0.972\n",
      "9780/10000 iterations done. At i=9780 => | Loss: 0.0740999728438392 | Accuracy:0.964\n",
      "9800/10000 iterations done. At i=9800 => | Loss: 0.07026752519131214 | Accuracy:0.976\n",
      "9820/10000 iterations done. At i=9820 => | Loss: 0.14067775533911306 | Accuracy:0.976\n",
      "9840/10000 iterations done. At i=9840 => | Loss: 0.06597707411260577 | Accuracy:0.972\n",
      "9860/10000 iterations done. At i=9860 => | Loss: 0.05513643876320311 | Accuracy:0.984\n",
      "9880/10000 iterations done. At i=9880 => | Loss: 0.20959448296922092 | Accuracy:0.94\n",
      "9900/10000 iterations done. At i=9900 => | Loss: 0.07690405041154771 | Accuracy:0.98\n",
      "9920/10000 iterations done. At i=9920 => | Loss: 0.11487568871576309 | Accuracy:0.964\n",
      "9940/10000 iterations done. At i=9940 => | Loss: 0.09899046372667086 | Accuracy:0.968\n",
      "9960/10000 iterations done. At i=9960 => | Loss: 0.13253040853330464 | Accuracy:0.948\n",
      "9980/10000 iterations done. At i=9980 => | Loss: 0.12069356566764437 | Accuracy:0.968\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "a = NeuralNetwork(4, [500, 350, 100, 50], 0.05)\n",
    "a.train(X,Y)\n",
    "y_pred = a.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cGdAM2SnfdtS"
   },
   "source": [
    "## Results and final comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CaIxaZyIlvX2",
    "outputId": "1b1d0e31-904d-48fc-8f71-979f15f15792"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5095\n"
     ]
    }
   ],
   "source": [
    "print(a.accuracy(y_pred,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3fpuRr-3fmNU"
   },
   "outputs": [],
   "source": [
    "def save_parameters(filename,y):\n",
    "  '''\n",
    "  This function is used to save the parameter\n",
    "  @param filename: Name of the file where classes are stored\n",
    "  @param y: The predicted values of y\n",
    "  '''\n",
    "  np.save(filename, y)\n",
    "\n",
    "save_parameters('ans1.npy', np.hstack(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "d5tGPqqCGfY7",
    "outputId": "fcbaef48-e797-43bf-d487-33b35febfdea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "['sample_data', '.config', 'data', 'ans1-at3761.npy']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print( os.getcwd() )\n",
    "print( os.listdir('/content') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pqXiSEmiGksn"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download( \"ans1.npy\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IkvBkJoyGr6n"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW_fullyConnected_at3761_tv655.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
